{
 "cells": [
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "metadata": {},
=======
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
>>>>>>> c6d1ee05bc57c5fd54f07ebf1b872e56a7781fab
   "source": [
    "<img src=\"Images/slide_1.png\" width=\"700\" height=\"700\">\n"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "metadata": {},
=======
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
>>>>>>> c6d1ee05bc57c5fd54f07ebf1b872e56a7781fab
   "source": [
    "<img src=\"Images/slide_2.png\" width=\"700\" height=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "\n",
    "- Decision Trees are considered one of the most mature, traditional algorithms in predictive analytics\n",
    "\n",
    "- They are most likely used for classification problems\n"
=======
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Decision Tree\n",
    "\n",
    "- Decision Trees are considered one of the most mature, traditional, algorithms in predictive analytics\n",
    "- They are typically used to solve classification problems through visual and explicit representations of decisions and decision making.\n",
    "- Think of them like a map where you follow each path according to your decision, and each path leads to a new choice to make until you reach the end.\n",
    "- They mimic the way you probably make decisions in your daily life:\n",
    "\n",
    "![decision_tree](./Images/dec_tree.png)\n",
    "\n",
    "### Terminology\n",
    "\n",
    "- **Root:** Our starting point for the tree. Note that a decision tree is drawn upside down since its root is at the top\n",
    "    - `Alone Or With Friends` is the root in the above example\n",
    "- **Branch:** Also known as an _edge_, these lead from condition to condition, down to the results\n",
    "    - `Sunny` or `Rainy` are branches in the above example\n",
    "- **Condition:** Also known as an _internal node_, this is the choice that needs to be made in order to figure out which branch to take.\n",
    "    - `Weather Outside?` is our condiition in the above example\n",
    "- **Leaf:** Also known as a _decision_, these are the final results that signify the classification of the data. There are no branches coming out of a leaf, only going in to it.\n",
    "    - `video games`, `soccer` and `movies` are all examples of a leaf"
>>>>>>> c6d1ee05bc57c5fd54f07ebf1b872e56a7781fab
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "metadata": {},
   "source": [
    "## Why and where we need Decision Tree ?\n",
    "\n",
    "- When features are Categorical "
=======
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Question to the class: Why and when do we need Decision Trees?\n",
    "\n",
    "### Shout out or type your answers!"
>>>>>>> c6d1ee05bc57c5fd54f07ebf1b872e56a7781fab
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "metadata": {},
   "source": [
    "## Practical Examples of Decision Tree\n",
    "\n",
    "- You’ll take a small dataset and see if you can learn anything from it\n",
    "\n",
    "- You’ll see if a decision tree can give you any insight as to how the eye doctor prescribes contact lenses\n",
    "\n",
    "- You can predict the type of lenses people will use and understand the underlying processes with a decision tree\n",
    "\n",
    "- Predict does a player plays tennis outside based on weather conditions\n"
=======
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Our answers:\n",
    "\n",
    "- When features are Categorical\n",
    "    - When we can classify data into known groups\n",
    "- When we want to model a set of sequential, hierarchical decisions that lead to some final result. This result is the known group that the data point would be categorized into\n",
    "- When we need to explain the reason for a particular decision\n",
    "- Example use cases:\n",
    "    - Sales and marketing departments might need a complete description of rules that influence the acquisition of a customer before they start their campaign activities\n",
    "    - Product planning (do we build this product or not?)\n",
    "    - Determining someone is a good or bad level of risk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The root and the leafs for Decision Tree are obtained based on: \n",
    "\n",
    "- Conditional Probability\n",
    "\n",
    "- Entropy\n",
    "\n",
    "- Information Gain"
>>>>>>> c6d1ee05bc57c5fd54f07ebf1b872e56a7781fab
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "metadata": {},
   "source": [
    "## Lens Dataset\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    " 3 Classes\n",
    "\n",
    " 1 : the patient should be fitted with hard contact lenses,\n",
    "\n",
    " 2 : the patient should be fitted with soft contact lenses,\n",
    "\n",
    " 3 : the patient should not be fitted with contact lenses.\n",
    " \n",
    "4 Features\n",
    "\n",
    "1. age of the patient: (1) young, (2) pre-presbyopic, (3) presbyopic\n",
    "\n",
    "2. spectacle prescription:  (1) myope, (2) hypermetrope\n",
    "\n",
    "3. astigmatic:     (1) no, (2) yes\n",
    "\n",
    "4. tear production rate:  (1) reduced, (2) normal\n",
    "\n",
    "<img src=\"Images/lens_data.png\" width=\"200\" height=\"200\">"
=======
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lens Dataset\n",
    "\n",
    "Let's review the Attribute Information that we know:\n",
    "\n",
    "We have 3 Classes (leaves/results)\n",
    "\n",
    "1. the patient should be fitted with _hard_ contact lenses,\n",
    "1. the patient should be fitted with _soft_ contact lenses,\n",
    "1. the patient should _not be fitted_ with contact lenses.\n",
    " \n",
    "The dataset has 4 Features (conditions):\n",
    "\n",
    "1. age of the patient: (1) young, (2) pre-presbyopic, (3) presbyopic\n",
    "1. spectacle prescription:  (1) myope, (2) hypermetrope\n",
    "1. astigmatic:     (1) no, (2) yes\n",
    "1. tear production rate:  (1) reduced, (2) normal\n",
    "\n",
    "Here is the data used for the Decision Tree:\n",
    "\n",
    "<img src=\"Images/lens_dataset.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lens Decision Tree Visualized\n",
    "\n",
    "This is ultimately what we want to build using the above dataset\n",
    "\n",
    "<img src=\"Images/lens_DT.png\" width=\"500\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Decision Trees are based on Entropy\n",
    "\n",
    "## Activity: Calculate the entropy for a coin\n",
    "\n",
    "**Entropy** shows the uncertainy of a random variable. The higher the entropy value, the more unncertain we are. Entropy is displayed as $H(X)$, where $X$ is a random variable\n",
    "\n",
    "The Entropy formula is the summation of probabilities multiplied by the log of probabilities:\n",
    "\n",
    "<!-- `Entropy(Coin) = sum(-p(outcome)xlog2p(outcome) for outcome in [H, T])` -->\n",
    "\n",
    "### Entropy of coin\n",
    "\n",
    "Given `p` stands for \"probability of\", \n",
    "\n",
    "for `outcome` in `[H,T]`:\n",
    "\n",
    "- $H(Coin) = \\sum -p(outcome) * log_2(p(outcome)$\n",
    "\n",
    "### Entropy of a fair coin\n",
    "\n",
    "<!-- `Entropy(Coin) = sum(-p(outcome)xlog2p(outcome) for p(outcome) in [p(H)=1/2, p(T)=1/2])` -->\n",
    "\n",
    "for `p(outcome)` in `[p(H)=0.5, p(T)=0.5])`:\n",
    "\n",
    "- $H(Coin) = \\sum -p(outcome) * log_2(p(outcome)$\n",
    "\n",
    "**Do the following in pairs:**\n",
    "\n",
    "- Create a function `entropy` that takes an array of probabilities as input, and returns the entropy using the formula above\n",
    "    - numpy's `array`, `log2`, and `sum` functions should be useful here\n",
    "- show that the fair coin has the largest entropy (uncertainty) by trying different values for  the probability of heads and tails\n",
    "    - i.e. show that a fair coin `[.5, .5]` has a larger entropy than a coin with `[.9, .1]` probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.4689955935892812\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def entropy(p):\n",
    "    H = np.array([-i*np.log2(i) for i in p]).sum()\n",
    "    return H\n",
    "    \n",
    "p = [.5, .5]\n",
    "print(entropy(p))\n",
    "\n",
    "p = [.9, .1]\n",
    "print(entropy(p))"
>>>>>>> c6d1ee05bc57c5fd54f07ebf1b872e56a7781fab
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "metadata": {},
   "source": [
    "<img src=\"Images/lens_DT.png\" width=\"500\" height=\"500\">"
=======
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Change p (probability of head and tail) and plot the entropy for different values of p\n",
    "\n",
    "<img src=\"Images/coin_entropy.jpg\" width=\"500\" height=\"500\">\n",
    "\n",
    " The fair coin has the highest entropy which means a fair coin has the highest uncertain result when toss a coin"
>>>>>>> c6d1ee05bc57c5fd54f07ebf1b872e56a7781fab
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "metadata": {},
   "source": [
    "## The root and the leafs for Decision Tree are obtained based on \n",
    "\n",
    "- Conditional Probability\n",
    "\n",
    "- Entropy\n",
    "\n",
    "- Information Gain"
=======
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How We'll Use Decision Trees Today\n",
    "\n",
    "- You’ll see if a decision tree can give you any insight as to how the eye doctor prescribes contact lenses\n",
    "\n",
    "- You can predict the type of lenses people will use and understand the underlying processes with a decision tree\n",
    "\n",
    "- Predict if a tennis player will play outside based on weather conditions\n"
>>>>>>> c6d1ee05bc57c5fd54f07ebf1b872e56a7781fab
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
<<<<<<< HEAD
   "metadata": {},
   "source": [
    "## Calculate the entropy for a fair coin\n",
    "\n",
    "Entropy shows the uncertainy about a random variable\n",
    "\n",
    "Show that the fair coin has the largest entropy (uncertainty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def entropy(p):\n",
    "    H = np.array([-i*np.log2(i) for i in p]).sum()\n",
    "    return H\n",
    "    \n",
    "p = [.5, .5]\n",
    "entropy(p)"
=======
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lens Dataset\n",
    "\n",
    "Let's review the Attribute Information that we know:\n",
    "\n",
    "We have 3 Classes (leaves/results)\n",
    "\n",
    "1. the patient should be fitted with _hard_ contact lenses,\n",
    "1. the patient should be fitted with _soft_ contact lenses,\n",
    "1. the patient should _not be fitted_ with contact lenses.\n",
    " \n",
    "The dataset has 4 Features (conditions):\n",
    "\n",
    "1. age of the patient: (1) young, (2) pre-presbyopic, (3) presbyopic\n",
    "1. spectacle prescription:  (1) myope, (2) hypermetrope\n",
    "1. astigmatic:     (1) no, (2) yes\n",
    "1. tear production rate:  (1) reduced, (2) normal\n",
    "\n",
    "Here is the data used for the Decision Tree:\n",
    "\n",
    "<img src=\"Images/lens_data.png\" width=\"200\" height=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lens Decision Tree Visualized\n",
    "\n",
    "<img src=\"Images/lens_DT.png\" width=\"500\" height=\"500\">"
>>>>>>> c6d1ee05bc57c5fd54f07ebf1b872e56a7781fab
   ]
  },
  {
   "cell_type": "markdown",
=======
>>>>>>> 7b19fc11f34a599b55ef26e00b0ce35f6acd4128
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "### Change p (probability of head and tale) and plot entropy for different p\n",
    "\n",
    "<img src=\"Images/coin_entropy.jpg\" width=\"500\" height=\"500\">\n",
    "\n",
    " The fair coin has the highest entropy which means a fair coin has the highest uncertain result when toss a coin"
=======
    "## Quick Review on Conditional Probability\n",
    "\n",
    "We'll be using conditional probability to solve the following activities. Before we do so, let's take 10 minutes to [review conditional probability from DS 1.1](https://github.com/Make-School-Courses/DS-1.1-Data-Analysis/blob/master/Notebooks/Applied_Probability.ipynb)\n",
    "\n",
    "We'll even see the same data set we're about to build a decision tree for!"
>>>>>>> c6d1ee05bc57c5fd54f07ebf1b872e56a7781fab
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "metadata": {},
   "source": [
    "## Lets build a Decision Tree for Tennis Data\n",
    "\n",
    "The following table informs about decision making factors to play tennis at outside based on 14 days data, for different weather conditions\n",
=======
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's build a Decision Tree for the Tennis Data\n",
    "\n",
    "The following table shows us the decision making factors used to play tennis outside based on 14 days of data for different weather conditions\n",
>>>>>>> c6d1ee05bc57c5fd54f07ebf1b872e56a7781fab
    "\n",
    "<img src=\"Images/dst_1.png\" width=\"400\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "metadata": {},
   "source": [
    "## Activity: Obtain the following quantitites:\n",
    "\n",
    "- Obtain the entropy of `PlayTennis` (Decision) column. Hint: p = [9/14, 5/14] which represents the probability that a player plays tennis or not\n",
    "\n",
    "`Entropy(Decision) = – (9/14) . log2(9/14) – (5/14) . log2(5/14) = 0.940`\n"
=======
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Activity: Obtain the following quantitites:\n",
    "\n",
    "**In groups of 3:** Using the [tennis dataset](./Datasets/tennis.txt), obtain the following quantities:\n",
    "\n",
    "### Entropy for PlayTennis:\n",
    "\n",
    "Obtain the entropy of the`PlayTennis` (Leaf/Decision) column. \n",
    "\n",
    "### Entropy for PlayTennis conditioned on Weak Wind factor\n",
    "\n",
    "Obtain the entropy of conditional probability `p(PlayTennis | Wind = Weak) = [2/8, 6/8]`\n",
    "\n",
    "### Entropy for PlayTennis conditioned on Strong Wind factor\n",
    "\n",
    "Obtain the entropy of conditional probability `p(PlayTennis | Wind = Strong) = [3/6, 3/6]`\n",
    "\n",
    "**Hints:**\n",
    "\n",
    "- p = [9/14, 5/14] which represents the probability that a player plays tennis (9/14 days) or not (5/14 days)\n",
    "- Remember your Entropy function from earlier\n"
>>>>>>> c6d1ee05bc57c5fd54f07ebf1b872e56a7781fab
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "metadata": {},
   "source": [
    "- Wind factor on Decision\n",
    "\n",
    "    - Obtain the entropy of conditional probability `p(PlayTennis | Wind = Weak) = [2/8, 6/8]`\n",
    "    \n",
    "    - <img src=\"Images/weak_wind_decision.png\" width=\"400\" height=\"400\">\n",
    "    \n",
    "    - Obtain the entropy of conditional probability `p(PlayTennis | Wind = Strong) = [3/6, 3/6]`\n",
    "    \n",
    "    -  <img src=\"Images/strong_wind_decision.png\" width=\"400\" height=\"400\">"
=======
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Solutions\n",
    "\n",
    "`Entropy(Decision) = – (9/14) . log2(9/14) – (5/14) . log2(5/14) = 0.940`\n",
    "\n",
    "<img src=\"Images/weak_wind_decision.png\" width=\"400\" height=\"400\">\n",
    "\n",
    "<img src=\"Images/strong_wind_decision.png\" width=\"400\" height=\"400\">"
>>>>>>> c6d1ee05bc57c5fd54f07ebf1b872e56a7781fab
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "## Obtain the Information Gain Between PlayTennis (Decision) and Wind\n",
    "\n",
    "- What is the probability that wind be weak? Hint = Count how many weak wind we have devide over how many sample we have.\n",
=======
    "## Information Gain\n",
    "\n",
    "**Information Gain** measures how much information a feature gives us about the decision (class). This is the main measurement used by a Decision Tree algorithm to construct a Decision Tree!\n",
    "\n",
    "- Decision Trees will always try to maximize information gain\n",
    "- The higher the information gain a feature has, the more likely it is to be tested first\n",
    "    - the feature with the highest information gain will be the first feature in the decision tree, and its branches will lead to the other features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Obtain the Information Gain Between PlayTennis (Decision) and Wind\n",
    "\n",
    "- What is the probability that wind be weak? \n",
    "\n",
<<<<<<< HEAD
    "Hint = Count how many weak wind we have devide over how many sample we have.\n",
>>>>>>> c6d1ee05bc57c5fd54f07ebf1b872e56a7781fab
=======
    "**Hint:** Count how many instannces of weak and strong winds we have divided by how many sample we have.\n",
>>>>>>> 7b19fc11f34a599b55ef26e00b0ce35f6acd4128
    "\n",
    "`p(Wind = Weak) = 8/ 14`\n",
    "\n",
    "`p(Wind = Strong) = 6/ 14`\n",
    "\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "- Information Gain(Decision, Wind) = \n",
    "\n",
=======
=======
    "Below are the formulas for finding Information Gain $I(X; Y)$ for a given decision $X$ and feature $Y$, and the Entropy for a decision given a feature\n",
    "\n",
>>>>>>> 7b19fc11f34a599b55ef26e00b0ce35f6acd4128
    "<img src=\"Images/Information_Gain.png\" width=\"=500\" height=\"500\">\n",
    "\n",
    "<img src=\"Images/Conditional_Entropy.png\" width=\"=500\" height=\"500\">\n",
    "\n",
    "Given `p` stands for \"probability of\", \n",
    "\n",
    "for `Wind = {Weak, Strong}`:\n",
    "\n",
    "- $I(Decision; Wind) = H(Decision) - \\sum p(Wind) * Entropy(Decision | Wind)$\n",
    "\n",
    "We can break this down further:\n",
    "\n",
    "$H(Decision) - \\sum p(Wind) * Entropy(Decision | Wind)$\n",
    "\n",
    "$=$ \n",
    "\n",
<<<<<<< HEAD
>>>>>>> c6d1ee05bc57c5fd54f07ebf1b872e56a7781fab
    "`Entropy(Decision) - p(Wind = Weak)Entropy(Decision | Wind = Weak ) - p(Wind = Strong)Entropy(Decision | Wind = Strong )`\n",
=======
    "$H(Decision) - (p(Wind = Weak) * H(Decision | Wind = Weak) + p(Wind = Strong) * H(Decision | Wind = Strong)) = 0.048$\n",
>>>>>>> 7b19fc11f34a599b55ef26e00b0ce35f6acd4128
    "\n",
    "<!-- `Information Gain(Decision, Wind) = Entropy(Decision) - sum(p(Wind) * Entropy(Decision | Wind )) for Wind = {Weak, Strong}`-->\n",
    "\n",
    "<!--`Entropy(Decision) - (p(Wind = Weak)Entropy(Decision | Wind = Weak ) + p(Wind = Strong)Entropy(Decision | Wind = Strong )) = 0.048`-->"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "metadata": {},
=======
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
>>>>>>> c6d1ee05bc57c5fd54f07ebf1b872e56a7781fab
   "source": [
    "## Other factors on Decision column\n",
    "\n",
    "We have applied similar calculation on the other features (columns)\n",
    "\n",
<<<<<<< HEAD
    "1 - Gain(Decision, Wind) = 0.048\n",
    "\n",
    "2 - Gain(Decision, Outlook) = 0.246\n",
    "\n",
    "3 - Gain(Decision, Temperature) = 0.029\n",
    "\n",
    "4 - Gain(Decision, Humidity) = 0.151"
=======
    "1 - Information Gain(Decision, Wind) = 0.048\n",
    "\n",
    "2 - Information Gain(Decision, Outlook) = 0.246\n",
    "\n",
    "3 - Information Gain(Decision, Temperature) = 0.029\n",
    "\n",
    "4 - Information Gain(Decision, Humidity) = 0.151"
>>>>>>> c6d1ee05bc57c5fd54f07ebf1b872e56a7781fab
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "### We can see Outlook and Decision has the highest Gain, so Outlook would be the root for the Decision Tree"
=======
    "### We can see Outlook and Decision have the highest Gain, so Outlook will be the root for the Decision Tree!"
>>>>>>> c6d1ee05bc57c5fd54f07ebf1b872e56a7781fab
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "## If keep continuing the calculation of Information Gain between nodes (features), \n",
    "\n",
    "## The tree is built based on the highest Information Gains"
=======
    "### If we keep continuing the calculation of Information Gain between nodes (features), we can build the tree based on the highest Information Gains from feature to feature\n",
    "\n",
    "Example: Information Gain (Outlook, Wind), Information Gain (Outlook, Temperature), Information Gain (Outlook, Humidity), and then finding the information gain after that, and so on and so forth"
>>>>>>> c6d1ee05bc57c5fd54f07ebf1b872e56a7781fab
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "metadata": {},
=======
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
>>>>>>> c6d1ee05bc57c5fd54f07ebf1b872e56a7781fab
   "source": [
    "## Build the decision tree with sklearn for tennis dataset\n",
    "\n",
    "#### For Decision Tree Visualization in Python:\n",
    "\n",
<<<<<<< HEAD
    "Packages that are needed:\n",
    "\n",
    "`conda install -c anaconda graphviz`\n",
    "\n",
    "`conda install -c anaconda pydot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (0.13.2)\r\n"
     ]
    }
   ],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install graphviz"
=======
    "Packages that are needed are below. Note that the multiple installs for graphviz are to ensure the executables install correctly to avoid [this error](https://stackoverflow.com/questions/28312534/graphvizs-executables-are-not-found-python-3-4):\n",
    "\n",
    "`conda install -c anaconda graphviz`\n",
    "\n",
    "`brew install graphviz`\n",
    "\n",
    "`conda install -c anaconda pydot`\n",
    "\n",
    "`conda install -c conda-forge pydotplus`"
>>>>>>> c6d1ee05bc57c5fd54f07ebf1b872e56a7781fab
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
<<<<<<< HEAD
   "metadata": {},
=======
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
>>>>>>> c6d1ee05bc57c5fd54f07ebf1b872e56a7781fab
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "           a     b       c       d    e\n",
      "1      Sunny   Hot    High    Weak   No\n",
      "2      Sunny   Hot    High  Strong   No\n",
      "3   Overcast   Hot    High    Weak  Yes\n",
      "4       Rain  Mild    High    Weak  Yes\n",
      "5       Rain  Cool  Normal    Weak  Yes\n",
      "6       Rain  Cool  Normal  Strong   No\n",
      "7   Overcast  Cool  Normal  Strong  Yes\n",
      "8      Sunny  Mild    High    Weak   No\n",
      "9      Sunny  Cool  Normal    Weak  Yes\n",
      "10      Rain  Mild  Normal    Weak  Yes\n",
      "11     Sunny  Mild  Normal  Strong  Yes\n",
      "12  Overcast  Mild    High  Strong  Yes\n",
      "13  Overcast   Hot  Normal    Weak  Yes\n",
      "14      Rain  Mild    High  Strong   No\n",
      "    a  b  c  d  e\n",
      "1   2  1  0  1  0\n",
      "2   2  1  0  0  0\n",
      "3   0  1  0  1  1\n",
      "4   1  2  0  1  1\n",
      "5   1  0  1  1  1\n",
      "6   1  0  1  0  0\n",
      "7   0  0  1  0  1\n",
      "8   2  2  0  1  0\n",
      "9   2  0  1  1  1\n",
      "10  1  2  1  1  1\n",
      "11  2  2  1  0  1\n",
      "12  0  2  0  0  1\n",
      "13  0  1  1  1  1\n",
      "14  1  2  0  0  0\n"
=======
      "     Outlook  Temp Humidity    Wind Play\n",
      "1      Sunny   Hot     High    Weak   No\n",
      "2      Sunny   Hot     High  Strong   No\n",
      "3   Overcast   Hot     High    Weak  Yes\n",
      "4       Rain  Mild     High    Weak  Yes\n",
      "5       Rain  Cool   Normal    Weak  Yes\n",
      "6       Rain  Cool   Normal  Strong   No\n",
      "7   Overcast  Cool   Normal  Strong  Yes\n",
      "8      Sunny  Mild     High    Weak   No\n",
      "9      Sunny  Cool   Normal    Weak  Yes\n",
      "10      Rain  Mild   Normal    Weak  Yes\n",
      "11     Sunny  Mild   Normal  Strong  Yes\n",
      "12  Overcast  Mild     High  Strong  Yes\n",
      "13  Overcast   Hot   Normal    Weak  Yes\n",
      "14      Rain  Mild     High  Strong   No\n",
      "    Outlook  Temp  Humidity  Wind  Play\n",
      "1         2     1         0     1     0\n",
      "2         2     1         0     0     0\n",
      "3         0     1         0     1     1\n",
      "4         1     2         0     1     1\n",
      "5         1     0         1     1     1\n",
      "6         1     0         1     0     0\n",
      "7         0     0         1     0     1\n",
      "8         2     2         0     1     0\n",
      "9         2     0         1     1     1\n",
      "10        1     2         1     1     1\n",
      "11        2     2         1     0     1\n",
      "12        0     2         0     0     1\n",
      "13        0     1         1     1     1\n",
      "14        1     2         0     0     0\n"
>>>>>>> c6d1ee05bc57c5fd54f07ebf1b872e56a7781fab
     ]
    },
    {
     "data": {
<<<<<<< HEAD
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"792pt\" height=\"676pt\"\n",
       " viewBox=\"0.00 0.00 792.00 676.01\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1.8124 1.8124) rotate(0) translate(4 369)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-369 433,-369 433,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"205.5,-365 102.5,-365 102.5,-297 205.5,-297 205.5,-365\"/>\n",
       "<text text-anchor=\"middle\" x=\"154\" y=\"-349.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Outlook &lt;= 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"154\" y=\"-334.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.94</text>\n",
       "<text text-anchor=\"middle\" x=\"154\" y=\"-319.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 14</text>\n",
       "<text text-anchor=\"middle\" x=\"154\" y=\"-304.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [5, 9]</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"141,-253.5 49,-253.5 49,-200.5 141,-200.5 141,-253.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"95\" y=\"-238.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"95\" y=\"-223.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 4</text>\n",
       "<text text-anchor=\"middle\" x=\"95\" y=\"-208.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 4]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M134.6812,-296.9465C128.4324,-285.9316 121.4888,-273.6922 115.1793,-262.5703\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"118.0362,-260.513 110.0576,-253.5422 111.9477,-263.967 118.0362,-260.513\"/>\n",
       "<text text-anchor=\"middle\" x=\"103.4046\" y=\"-273.9407\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"269,-261 159,-261 159,-193 269,-193 269,-261\"/>\n",
       "<text text-anchor=\"middle\" x=\"214\" y=\"-245.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Humidity &lt;= 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"214\" y=\"-230.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 1.0</text>\n",
       "<text text-anchor=\"middle\" x=\"214\" y=\"-215.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 10</text>\n",
       "<text text-anchor=\"middle\" x=\"214\" y=\"-200.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [5, 5]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M173.6462,-296.9465C178.619,-288.3271 184.0243,-278.9579 189.2148,-269.9611\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"192.344,-271.5409 194.3096,-261.13 186.2807,-268.0428 192.344,-271.5409\"/>\n",
       "<text text-anchor=\"middle\" x=\"200.7878\" y=\"-281.5761\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"205,-157 99,-157 99,-89 205,-89 205,-157\"/>\n",
       "<text text-anchor=\"middle\" x=\"152\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Outlook &lt;= 1.5</text>\n",
       "<text text-anchor=\"middle\" x=\"152\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.722</text>\n",
       "<text text-anchor=\"middle\" x=\"152\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 5</text>\n",
       "<text text-anchor=\"middle\" x=\"152\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [4, 1]</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M193.6989,-192.9465C188.5604,-184.3271 182.9749,-174.9579 177.6114,-165.9611\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"180.4737,-163.9272 172.3467,-157.13 174.4611,-167.5117 180.4737,-163.9272\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"329,-157 223,-157 223,-89 329,-89 329,-157\"/>\n",
       "<text text-anchor=\"middle\" x=\"276\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Wind &lt;= 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"276\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.722</text>\n",
       "<text text-anchor=\"middle\" x=\"276\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 5</text>\n",
       "<text text-anchor=\"middle\" x=\"276\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [1, 4]</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>2&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M234.3011,-192.9465C239.4396,-184.3271 245.0251,-174.9579 250.3886,-165.9611\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"253.5389,-167.5117 255.6533,-157.13 247.5263,-163.9272 253.5389,-167.5117\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"92,-53 0,-53 0,0 92,0 92,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"46\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 1.0</text>\n",
       "<text text-anchor=\"middle\" x=\"46\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 2</text>\n",
       "<text text-anchor=\"middle\" x=\"46\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [1, 1]</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>3&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M114.6284,-88.9777C104.3688,-79.6376 93.2511,-69.5163 83.0118,-60.1947\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"85.1326,-57.3923 75.3817,-53.2485 80.4202,-62.5686 85.1326,-57.3923\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"202,-53 110,-53 110,0 202,0 202,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"156\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"156\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3</text>\n",
       "<text text-anchor=\"middle\" x=\"156\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [3, 0]</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>3&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M153.4103,-88.9777C153.7519,-80.7364 154.1187,-71.887 154.4657,-63.5153\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"157.974,-63.3849 154.8913,-53.2485 150.98,-63.0949 157.974,-63.3849\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"319,-53 227,-53 227,0 319,0 319,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"273\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 1.0</text>\n",
       "<text text-anchor=\"middle\" x=\"273\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 2</text>\n",
       "<text text-anchor=\"middle\" x=\"273\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [1, 1]</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>6&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M274.9423,-88.9777C274.6861,-80.7364 274.411,-71.887 274.1507,-63.5153\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"277.6407,-63.1349 273.8316,-53.2485 270.6441,-63.3524 277.6407,-63.1349\"/>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>8</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"429,-53 337,-53 337,0 429,0 429,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"383\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"383\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3</text>\n",
       "<text text-anchor=\"middle\" x=\"383\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 3]</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>6&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M313.7242,-88.9777C324.0806,-79.6376 335.3031,-69.5163 345.639,-60.1947\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"348.2591,-62.5449 353.3411,-53.2485 343.5709,-57.3467 348.2591,-62.5449\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x11dc67610>"
=======
      "text/plain": [
       "True"
>>>>>>> c6d1ee05bc57c5fd54f07ebf1b872e56a7781fab
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
<<<<<<< HEAD
    "import graphviz\n",
    "\n",
    "\n",
    "data = pd.read_csv('Datasets/tennis.txt', delimiter=\"\\t\", header=None, names=['a', 'b', 'c', 'd', 'e'])\n",
    "print(data)\n",
    "\n",
    "data_encoded = data.apply(preprocessing.LabelEncoder().fit_transform)\n",
    "print(data_encoded)\n",
    "\n",
    "#\n",
=======
    "\n",
    "# read in the tennis data, need the extra parameters since it's a txt file\n",
    "data = pd.read_csv('./Datasets/tennis.txt', delimiter=\"\\t\", header=None, names=['Outlook', 'Temp', 'Humidity', 'Wind', 'Play'])\n",
    "print(data)\n",
    "\n",
    "# encode the data so we can use it with our decision tree,\n",
    "# by converting categories into numbers\n",
    "data_encoded = data.apply(preprocessing.LabelEncoder().fit_transform)\n",
    "print(data_encoded)\n",
    "\n",
<<<<<<< HEAD
    "# create our decision tree classifier\n",
>>>>>>> c6d1ee05bc57c5fd54f07ebf1b872e56a7781fab
=======
    "# create our decision tree classifier with entropy\n",
>>>>>>> 7b19fc11f34a599b55ef26e00b0ce35f6acd4128
    "clf = DecisionTreeClassifier(criterion='entropy', max_depth=3)\n",
    "\n",
    "# one_hot_data = pd.get_dummies(data[['a', 'b', 'c', 'd']], drop_first=True)\n",
    "# print(one_hot_data)\n",
<<<<<<< HEAD
    "clf.fit(data_encoded[['a', 'b', 'c', 'd']], data_encoded['e'])\n",
    "\n",
    "\n",
=======
    "\n",
    "# provide our feature array and target array (1-item),\n",
    "# and train the model using a decision tree\n",
    "clf.fit(data_encoded[['Outlook', 'Temp', 'Humidity', 'Wind']], data_encoded['Play'])\n",
    "\n",
    "# export our decision tree into data that can be plotted\n",
>>>>>>> c6d1ee05bc57c5fd54f07ebf1b872e56a7781fab
    "dot_data = export_graphviz(clf, out_file=None, feature_names=['Outlook', 'Temp.', 'Humidity', 'Wind'])\n",
    "\n",
    "# Draw graph\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
<<<<<<< HEAD
    "#graph.write_png('Images/tennis_tree.png')\n",
    "\n",
    "graph.write_png('original_tree.png')\n",
    "graph.set_size('\"11,12!\"')\n",
    "graph.write_png('resized_tree.png')\n",
    "gvz_graph = graphviz.Source(graph.to_string())\n",
    "gvz_graph"
=======
    "graph.write_png('tennis_tree.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity: Information Gain between Feature and Target\n",
    "\n",
    "**In groups of 3:** Write a function that takes a Tennis pandas dataframe, one feature (for example Wind) and target column (Decision) as input, then returns the information gain between the feature and the target. This should work for any feature (Outlook, Temp, Humidity, Wind) and the target (Play) for the given dataset.\n",
    "\n",
    "Use the hints and starter code given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Outlook  Temp Humidity    Wind Play\n",
      "1      Sunny   Hot     High    Weak   No\n",
      "2      Sunny   Hot     High  Strong   No\n",
      "3   Overcast   Hot     High    Weak  Yes\n",
      "4       Rain  Mild     High    Weak  Yes\n",
      "5       Rain  Cool   Normal    Weak  Yes\n",
      "6       Rain  Cool   Normal  Strong   No\n",
      "7   Overcast  Cool   Normal  Strong  Yes\n",
      "8      Sunny  Mild     High    Weak   No\n",
      "9      Sunny  Cool   Normal    Weak  Yes\n",
      "10      Rain  Mild   Normal    Weak  Yes\n",
      "11     Sunny  Mild   Normal  Strong  Yes\n",
      "12  Overcast  Mild     High  Strong  Yes\n",
      "13  Overcast   Hot   Normal    Weak  Yes\n",
      "14      Rain  Mild     High  Strong   No\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('tennis.txt', delimiter=\"\\t\", header=None, names=['Outlook', 'Temp', 'Humidity', 'Wind', 'Play'])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hint: helper function for entopy\n",
    "import numpy as np\n",
    "\n",
    "def entropy(p):\n",
    "    H = np.array([-i*np.log2(i) for i in p]).sum()\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'No': 0.25, 'Yes': 0.75}\n",
      "{'No': 0.5, 'Yes': 0.5}\n"
     ]
    }
   ],
   "source": [
    "# hint: helper function that takes a dataset (df) and one of its features (c1),\n",
    "# decision (c2), and condition of the feature (condition) as input, and outputs\n",
    "# the condiitional probability\n",
    "def conditional_prob(df, c1, c2, condition):\n",
    "    df_new = df[df[c1] == condition][c2]\n",
    "    s = df_new.unique()\n",
    "    population_size = len(df_new)\n",
    "    pr = {}\n",
    "    for i in s:\n",
    "        pr[i] = len(df[(df[c1] == condition) & (df[c2]== i)]) / population_size\n",
    "    \n",
    "    return pr\n",
    "\n",
    "# what are the probabilities of Play  given Wind is Weak?\n",
    "print(conditional_prob(data,'Wind', 'Play', 'Weak'))\n",
    "\n",
    "# what are the probabilities of Play given Wind is Strong?\n",
    "print(conditional_prob(data, 'Wind', 'Play', 'Strong'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs: dataset (df), a feature from the dataset (feature), and the target (decision)\n",
    "# returns: information gain between feature and decision\n",
    "def info_gain(df, feature, decision):\n",
    "    # obtain the entropy of the decision\n",
    "    dict_decision = dict(df[decision].value_counts())\n",
    "    prob_decision = [q for (p,q) in dict_decision.items()]/sum(dict_decision.values())\n",
    "    entropy_decision = entropy(prob_decision)\n",
    "#     print(entropy_decision)\n",
    "    \n",
    "    # obtain the probabilities of the feature\n",
    "    # example: for Wind, obtain the probabilities of Strong and Weak\n",
    "    dict_feature = dict(df[feature].value_counts())\n",
    "    dict_prob_feature = {}\n",
    "    for (p,q) in dict_feature.items():\n",
    "        dict_prob_feature[p] = q/sum(dict_feature.values())\n",
    "#     print(dict_prob_feature)\n",
    "    \n",
    "    # obtain the probability of the decision,\n",
    "    # for all possible values of the feature (conditions)\n",
    "    conditions = df[feature].unique()\n",
    "    dict_ = {}\n",
    "    for condition in conditions:\n",
    "        dict_[condition] = conditional_prob(df, feature, decision, condition)\n",
    "#     print(dict_)\n",
    "    \n",
    "    # Given the above metrics, calculate the information gain\n",
    "    # between the feature and the decision using the formula we learned\n",
    "    S = 0\n",
    "    for (i,j) in dict_.items():\n",
    "#         print(i,j)\n",
    "        prob_condition = list(dict_[i].values())\n",
    "#         print(entropy_condition)\n",
    "        S = S + dict_prob_feature[i]*entropy(prob_condition)\n",
    "#         print(dict_prob_feature[i]*entropy(entropy_condition))\n",
    "    print(entropy_decision - S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04812703040826949\n",
      "0.15183550136234159\n",
      "0.02922256565895487\n",
      "0.24674981977443933\n"
     ]
    }
   ],
   "source": [
    "info_gain(data, 'Wind', 'Play')\n",
    "info_gain(data, 'Humidity', 'Play')\n",
    "info_gain(data, 'Temp', 'Play')\n",
    "info_gain(data, 'Outlook', 'Play')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: We can show the information gain between any feature with itself is equal to its entropy: \n",
    "\n",
    "- $I(X, X) = H(X)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5774062828523454\n",
      "1.5774062828523454\n",
      "1.5566567074628228\n",
      "1.5566567074628228\n",
      "1.0\n",
      "1.0\n",
      "0.9852281360342515\n",
      "0.9852281360342515\n",
      "0.9402859586706311\n",
      "0.9402859586706311\n"
     ]
    }
   ],
   "source": [
    "for i in ['Outlook', 'Temp', 'Humidity', 'Wind', 'Play']:\n",
    "    p = [m/sum(data[i].value_counts().to_dict().values()) for m in list(data[i].value_counts().to_dict().values())]\n",
    "    print(entropy(p))\n",
    "    info_gain(data, i, i)"
>>>>>>> c6d1ee05bc57c5fd54f07ebf1b872e56a7781fab
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary:\n",
    "\n",
    "- A decision tree is a decision support tool that uses a tree-like model of decisions and their possible consequences\n",
    "\n",
<<<<<<< HEAD
    "- Decision Tree provides an effective method of Decision Making \n",
    "\n",
    "- The best feature of using trees for analytics - easy to interpret and explain to executives\n",
    "\n",
    "- The mechanism behind DT are maximizing information gains while have different options "
=======
    "- Decision Trees provide an effective method of Decision Making \n",
    "\n",
    "- The best characteristic of using trees for analytics -> easy to interpret and explain to executives\n",
    "\n",
    "- The mechanism behind Decision Trees is maximizing information gains while have different options "
>>>>>>> c6d1ee05bc57c5fd54f07ebf1b872e56a7781fab
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "metadata": {},
=======
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
>>>>>>> c6d1ee05bc57c5fd54f07ebf1b872e56a7781fab
   "source": [
    "## Resources:\n",
    "\n",
    "- https://sefiks.com/2017/11/20/a-step-by-step-id3-decision-tree-example/\n",
    "\n",
    "- https://heartbeat.fritz.ai/introduction-to-decision-tree-learning-cd604f85e236\n",
    "\n",
    "- https://journals.plos.org/plosone/article/figure/image?id=10.1371/journal.pone.0161696.g002&size=inline\n",
<<<<<<< HEAD
    "    "
   ]
  }
 ],
 "metadata": {
=======
    "\n",
    "- https://medium.com/coinmonks/what-is-entropy-and-why-information-gain-is-matter-4e85d46d2f01\n",
    "\n",
    "- https://pdfs.semanticscholar.org/26e0/a38b6a81802d9d3c7fdd430befda7ea6bf11.pdf\n",
    "\n",
    "DT Visualization:\n",
    "\n",
    "- https://explained.ai/decision-tree-viz/\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Mild': 6, 'Cool': 4, 'Hot': 4}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Temp'].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 4, 4]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data['Temp'].value_counts().to_dict().values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data['Temp'].value_counts().to_dict().values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5566567074628228\n"
     ]
    }
   ],
   "source": [
    "p = [m/sum(data['Temp'].value_counts().to_dict().values()) for m in list(data['Temp'].value_counts().to_dict().values())]\n",
    "\n",
    "print(entropy(p))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
>>>>>>> c6d1ee05bc57c5fd54f07ebf1b872e56a7781fab
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.7.6"
=======
   "version": "3.7.5"
>>>>>>> c6d1ee05bc57c5fd54f07ebf1b872e56a7781fab
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
