{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"Images/slide_1.png\" width=\"700\" height=\"700\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"Images/slide_2.png\" width=\"700\" height=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Decision Tree\n",
    "\n",
    "- Decision Trees are considered one of the most mature, traditional, algorithms in predictive analytics\n",
    "- They are typically used to solve classification problems through visual and explicit representations of decisions and decision making.\n",
    "- Think of them like a map where you follow each path according to your decision, and each path leads to a new choice to make until you reach the end.\n",
    "- They mimic the way you probably make decisions in your daily life:\n",
    "\n",
    "![decision_tree](./Images/dec_tree.png)\n",
    "\n",
    "### Terminology\n",
    "\n",
    "- **Root:** Our starting point for the tree. Note that a decision tree is drawn upside down since its root is at the top\n",
    "    - `Alone Or With Friends` is the root in the above example\n",
    "- **Branch:** Also known as an _edge_, these lead from condition to condition, down to the results\n",
    "    - `Sunny` or `Rainy` are branches in the above example\n",
    "- **Condition:** Also known as an _internal node_, this is the choice that needs to be made in order to figure out which branch to take.\n",
    "    - `Weather Outside?` is our condiition in the above example\n",
    "- **Leaf:** Also known as a _decision_, these are the final results that signify the classification of the data. There are no branches coming out of a leaf, only going in to it.\n",
    "    - `video games`, `soccer` and `movies` are all examples of a leaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Question to the class: Why and when do we need Decision Trees?\n",
    "\n",
    "### Shout out or type your answers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Our answers:\n",
    "\n",
    "- When features are Categorical\n",
    "    - When we can classify data into known groups\n",
    "- When we want to model a set of sequential, hierarchical decisions that lead to some final result. This result is the known group that the data point would be categorized into\n",
    "- When we need to explain the reason for a particular decision\n",
    "- Example use cases:\n",
    "    - Sales and marketing departments might need a complete description of rules that influence the acquisition of a customer before they start their campaign activities\n",
    "    - Product planning (do we build this product or not?)\n",
    "    - Determining someone is a good or bad level of risk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The root and the leafs for Decision Tree are obtained based on: \n",
    "\n",
    "- Conditional Probability\n",
    "\n",
    "- Entropy\n",
    "\n",
    "- Information Gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Decision Trees are based on Entropy\n",
    "\n",
    "## Activity: Calculate the entropy for a coin\n",
    "\n",
    "**Entropy** shows the uncertainy of a random variable\n",
    "\n",
    "The Entropy formula is the summation of probabilities multiplied by the log of probabilities:\n",
    "\n",
    "`Entropy(Coin) = sum(-p(outcome)xlog2p(outcome) for outcome in [H, T])`\n",
    "\n",
    "for a fair coin: `Entropy(Coin) = sum(-p(outcome)xlog2p(outcome) for p(outcome) in [p(H)=1/2, p(T)=1/2])`\n",
    "\n",
    "**Do the following in pairs:**\n",
    "\n",
    "- Create a function `entropy` that takes an array of probabilities as input, and returns the entropy using the formula above\n",
    "    - numpy's `array`, `log2`, and `sum` functions should be useful here\n",
    "- show that the fair coin has the largest entropy (uncertainty) by trying different values for  the probability of heads and tails\n",
    "    - i.e. show that a fair coin `[.5, .5]` has a larger entropy than a coin with `[.9, .1]` probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.4689955935892812\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def entropy(p):\n",
    "    H = np.array([-i*np.log2(i) for i in p]).sum()\n",
    "    return H\n",
    "    \n",
    "p = [.5, .5]\n",
    "print(entropy(p))\n",
    "\n",
    "p = [.9, .1]\n",
    "print(entropy(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Change p (probability of head and tail) and plot the entropy for different values of p\n",
    "\n",
    "<img src=\"Images/coin_entropy.jpg\" width=\"500\" height=\"500\">\n",
    "\n",
    " The fair coin has the highest entropy which means a fair coin has the highest uncertain result when toss a coin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How We'll Use Decision Trees Today\n",
    "\n",
    "- You’ll see if a decision tree can give you any insight as to how the eye doctor prescribes contact lenses\n",
    "\n",
    "- You can predict the type of lenses people will use and understand the underlying processes with a decision tree\n",
    "\n",
    "- Predict if a tennis player will play outside based on weather conditions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lens Dataset\n",
    "\n",
    "Let's review the Attribute Information that we know:\n",
    "\n",
    "We have 3 Classes (leaves/results)\n",
    "\n",
    "1. the patient should be fitted with _hard_ contact lenses,\n",
    "1. the patient should be fitted with _soft_ contact lenses,\n",
    "1. the patient should _not be fitted_ with contact lenses.\n",
    " \n",
    "The dataset has 4 Features (conditions):\n",
    "\n",
    "1. age of the patient: (1) young, (2) pre-presbyopic, (3) presbyopic\n",
    "1. spectacle prescription:  (1) myope, (2) hypermetrope\n",
    "1. astigmatic:     (1) no, (2) yes\n",
    "1. tear production rate:  (1) reduced, (2) normal\n",
    "\n",
    "Here is the data used for the Decision Tree:\n",
    "\n",
    "<img src=\"Images/lens_data.png\" width=\"200\" height=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lens Decision Tree Visualized\n",
    "\n",
    "<img src=\"Images/lens_DT.png\" width=\"500\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Review on Conditional Probability\n",
    "\n",
    "We'll be using conditional probability to solve the following activities. Before we do so, let's take 10 minutes to [review conditional probability from DS 1.1](https://github.com/Make-School-Courses/DS-1.1-Data-Analysis/blob/master/Notebooks/Applied_Probability.ipynb)\n",
    "\n",
    "We'll even see the same data set we're about to build a decision tree for!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
<<<<<<< HEAD
    "## Lets build a Decision Tree for Tennis Data\n",
=======
    "## Let's build a Decision Tree for the Tennis Data\n",
>>>>>>> c6d1ee05bc57c5fd54f07ebf1b872e56a7781fab
    "\n",
    "The following table shows us the decision making factors used to play tennis outside based on 14 days of data for different weather conditions\n",
    "\n",
    "<img src=\"Images/dst_1.png\" width=\"400\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Activity: Obtain the following quantitites:\n",
    "\n",
    "**In groups of 3:** Using the [tennis dataset](./Datasets/tennis.txt), obtain the following quantities:\n",
    "\n",
    "### Entropy for PlayTennis:\n",
    "\n",
    "Obtain the entropy of the`PlayTennis` (Leaf/Decision) column. \n",
    "\n",
    "### Wind factor: Weak\n",
    "\n",
    "Obtain the entropy of conditional probability `p(PlayTennis | Wind = Weak) = [2/8, 6/8]`\n",
    "\n",
    "### Wind Factor: Strong\n",
    "\n",
    "Obtain the entropy of conditional probability `p(PlayTennis | Wind = Strong) = [3/6, 3/6]`\n",
    "\n",
    "**Hints:**\n",
    "\n",
    "- p = [9/14, 5/14] which represents the probability that a player plays tennis (9/14 days) or not (5/14 days)\n",
    "- Remember your Entropy function from earlier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Solutions\n",
    "\n",
    "`Entropy(Decision) = – (9/14) . log2(9/14) – (5/14) . log2(5/14) = 0.940`\n",
    "\n",
    "<img src=\"Images/weak_wind_decision.png\" width=\"400\" height=\"400\">\n",
    "\n",
    "<img src=\"Images/strong_wind_decision.png\" width=\"400\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information Gain\n",
    "\n",
    "**Information Gain** measures how much information a feature gives us about the decision (class). This is the main measurement used by a Decision Tree algorithm to construct a Decision Tree!\n",
    "\n",
    "- Decision Trees will always try to maximize information gain\n",
    "- The higher the information gain a feature has, the more likely it is to be tested first\n",
    "    - the feature with the highest information gain will be the first feature in the decision tree, and its branches will lead to the other features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Obtain the Information Gain Between PlayTennis (Decision) and Wind\n",
    "\n",
    "- What is the probability that wind be weak? \n",
    "\n",
    "Hint = Count how many weak wind we have devide over how many sample we have.\n",
    "\n",
    "`p(Wind = Weak) = 8/ 14`\n",
    "\n",
    "`p(Wind = Strong) = 6/ 14`\n",
    "\n",
    "<img src=\"Images/Information_Gain.png\" width=\"=500\" height=\"500\">\n",
    "\n",
    "<img src=\"Images/Conditional_Entropy.png\" width=\"=500\" height=\"500\">\n",
    "\n",
    "- https://pdfs.semanticscholar.org/26e0/a38b6a81802d9d3c7fdd430befda7ea6bf11.pdf\n",
    "\n",
    "- Information Gain(Decision, Wind) = \n",
    "\n",
    "`Entropy(Decision) - sum(Entropy(Decision | Wind ) p(Wind)) for Wind = {Weak, Strong}`\n",
    "\n",
    "`Entropy(Decision) - p(Wind = Weak)Entropy(Decision | Wind = Weak ) - p(Wind = Strong)Entropy(Decision | Wind = Strong )`\n",
    "\n",
    "= 0.048"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Other factors on Decision column\n",
    "\n",
    "We have applied similar calculation on the other features (columns)\n",
    "\n",
    "1 - Information Gain(Decision, Wind) = 0.048\n",
    "\n",
    "2 - Information Gain(Decision, Outlook) = 0.246\n",
    "\n",
    "3 - Information Gain(Decision, Temperature) = 0.029\n",
    "\n",
    "4 - Information Gain(Decision, Humidity) = 0.151"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can see Outlook and Decision have the highest Gain, so Outlook will be the root for the Decision Tree!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If we keep continuing the calculation of Information Gain between nodes (features), we can build the tree based on the highest Information Gains from feature to feature\n",
    "\n",
    "Example: Information Gain (Outlook, Wind), Information Gain (Outlook, Temperature), Information Gain (Outlook, Humidity), and then finding the information gain after that, and so on and so forth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Activity: Build the decision tree with sklearn for tennis dataset\n",
    "\n",
    "#### For Decision Tree Visualization in Python:\n",
    "\n",
    "Packages that are needed are below. Note that the multiple installs for graphviz are to ensure the executables install correctly to avoid [this error](https://stackoverflow.com/questions/28312534/graphvizs-executables-are-not-found-python-3-4):\n",
    "\n",
    "`conda install -c anaconda graphviz`\n",
    "\n",
    "`brew install graphviz`\n",
    "\n",
    "`conda install -c anaconda pydot`\n",
    "\n",
    "`conda install -c conda-forge pydotplus`"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (0.13.2)\r\n"
     ]
    }
   ],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
=======
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
>>>>>>> c6d1ee05bc57c5fd54f07ebf1b872e56a7781fab
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "           a     b       c       d    e\n",
      "1      Sunny   Hot    High    Weak   No\n",
      "2      Sunny   Hot    High  Strong   No\n",
      "3   Overcast   Hot    High    Weak  Yes\n",
      "4       Rain  Mild    High    Weak  Yes\n",
      "5       Rain  Cool  Normal    Weak  Yes\n",
      "6       Rain  Cool  Normal  Strong   No\n",
      "7   Overcast  Cool  Normal  Strong  Yes\n",
      "8      Sunny  Mild    High    Weak   No\n",
      "9      Sunny  Cool  Normal    Weak  Yes\n",
      "10      Rain  Mild  Normal    Weak  Yes\n",
      "11     Sunny  Mild  Normal  Strong  Yes\n",
      "12  Overcast  Mild    High  Strong  Yes\n",
      "13  Overcast   Hot  Normal    Weak  Yes\n",
      "14      Rain  Mild    High  Strong   No\n",
      "    a  b  c  d  e\n",
      "1   2  1  0  1  0\n",
      "2   2  1  0  0  0\n",
      "3   0  1  0  1  1\n",
      "4   1  2  0  1  1\n",
      "5   1  0  1  1  1\n",
      "6   1  0  1  0  0\n",
      "7   0  0  1  0  1\n",
      "8   2  2  0  1  0\n",
      "9   2  0  1  1  1\n",
      "10  1  2  1  1  1\n",
      "11  2  2  1  0  1\n",
      "12  0  2  0  0  1\n",
      "13  0  1  1  1  1\n",
      "14  1  2  0  0  0\n"
=======
      "     Outlook  Temp Humidity    Wind Play\n",
      "1      Sunny   Hot     High    Weak   No\n",
      "2      Sunny   Hot     High  Strong   No\n",
      "3   Overcast   Hot     High    Weak  Yes\n",
      "4       Rain  Mild     High    Weak  Yes\n",
      "5       Rain  Cool   Normal    Weak  Yes\n",
      "6       Rain  Cool   Normal  Strong   No\n",
      "7   Overcast  Cool   Normal  Strong  Yes\n",
      "8      Sunny  Mild     High    Weak   No\n",
      "9      Sunny  Cool   Normal    Weak  Yes\n",
      "10      Rain  Mild   Normal    Weak  Yes\n",
      "11     Sunny  Mild   Normal  Strong  Yes\n",
      "12  Overcast  Mild     High  Strong  Yes\n",
      "13  Overcast   Hot   Normal    Weak  Yes\n",
      "14      Rain  Mild     High  Strong   No\n",
      "    Outlook  Temp  Humidity  Wind  Play\n",
      "1         2     1         0     1     0\n",
      "2         2     1         0     0     0\n",
      "3         0     1         0     1     1\n",
      "4         1     2         0     1     1\n",
      "5         1     0         1     1     1\n",
      "6         1     0         1     0     0\n",
      "7         0     0         1     0     1\n",
      "8         2     2         0     1     0\n",
      "9         2     0         1     1     1\n",
      "10        1     2         1     1     1\n",
      "11        2     2         1     0     1\n",
      "12        0     2         0     0     1\n",
      "13        0     1         1     1     1\n",
      "14        1     2         0     0     0\n"
>>>>>>> c6d1ee05bc57c5fd54f07ebf1b872e56a7781fab
     ]
    },
    {
     "data": {
<<<<<<< HEAD
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"792pt\" height=\"676pt\"\n",
       " viewBox=\"0.00 0.00 792.00 676.01\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1.8124 1.8124) rotate(0) translate(4 369)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-369 433,-369 433,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"205.5,-365 102.5,-365 102.5,-297 205.5,-297 205.5,-365\"/>\n",
       "<text text-anchor=\"middle\" x=\"154\" y=\"-349.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Outlook &lt;= 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"154\" y=\"-334.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.94</text>\n",
       "<text text-anchor=\"middle\" x=\"154\" y=\"-319.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 14</text>\n",
       "<text text-anchor=\"middle\" x=\"154\" y=\"-304.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [5, 9]</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"141,-253.5 49,-253.5 49,-200.5 141,-200.5 141,-253.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"95\" y=\"-238.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"95\" y=\"-223.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 4</text>\n",
       "<text text-anchor=\"middle\" x=\"95\" y=\"-208.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 4]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M134.6812,-296.9465C128.4324,-285.9316 121.4888,-273.6922 115.1793,-262.5703\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"118.0362,-260.513 110.0576,-253.5422 111.9477,-263.967 118.0362,-260.513\"/>\n",
       "<text text-anchor=\"middle\" x=\"103.4046\" y=\"-273.9407\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"269,-261 159,-261 159,-193 269,-193 269,-261\"/>\n",
       "<text text-anchor=\"middle\" x=\"214\" y=\"-245.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Humidity &lt;= 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"214\" y=\"-230.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 1.0</text>\n",
       "<text text-anchor=\"middle\" x=\"214\" y=\"-215.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 10</text>\n",
       "<text text-anchor=\"middle\" x=\"214\" y=\"-200.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [5, 5]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M173.6462,-296.9465C178.619,-288.3271 184.0243,-278.9579 189.2148,-269.9611\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"192.344,-271.5409 194.3096,-261.13 186.2807,-268.0428 192.344,-271.5409\"/>\n",
       "<text text-anchor=\"middle\" x=\"200.7878\" y=\"-281.5761\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"205,-157 99,-157 99,-89 205,-89 205,-157\"/>\n",
       "<text text-anchor=\"middle\" x=\"152\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Outlook &lt;= 1.5</text>\n",
       "<text text-anchor=\"middle\" x=\"152\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.722</text>\n",
       "<text text-anchor=\"middle\" x=\"152\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 5</text>\n",
       "<text text-anchor=\"middle\" x=\"152\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [4, 1]</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M193.6989,-192.9465C188.5604,-184.3271 182.9749,-174.9579 177.6114,-165.9611\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"180.4737,-163.9272 172.3467,-157.13 174.4611,-167.5117 180.4737,-163.9272\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"329,-157 223,-157 223,-89 329,-89 329,-157\"/>\n",
       "<text text-anchor=\"middle\" x=\"276\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Wind &lt;= 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"276\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.722</text>\n",
       "<text text-anchor=\"middle\" x=\"276\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 5</text>\n",
       "<text text-anchor=\"middle\" x=\"276\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [1, 4]</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>2&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M234.3011,-192.9465C239.4396,-184.3271 245.0251,-174.9579 250.3886,-165.9611\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"253.5389,-167.5117 255.6533,-157.13 247.5263,-163.9272 253.5389,-167.5117\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"92,-53 0,-53 0,0 92,0 92,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"46\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 1.0</text>\n",
       "<text text-anchor=\"middle\" x=\"46\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 2</text>\n",
       "<text text-anchor=\"middle\" x=\"46\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [1, 1]</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>3&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M114.6284,-88.9777C104.3688,-79.6376 93.2511,-69.5163 83.0118,-60.1947\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"85.1326,-57.3923 75.3817,-53.2485 80.4202,-62.5686 85.1326,-57.3923\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"202,-53 110,-53 110,0 202,0 202,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"156\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"156\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3</text>\n",
       "<text text-anchor=\"middle\" x=\"156\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [3, 0]</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>3&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M153.4103,-88.9777C153.7519,-80.7364 154.1187,-71.887 154.4657,-63.5153\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"157.974,-63.3849 154.8913,-53.2485 150.98,-63.0949 157.974,-63.3849\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"319,-53 227,-53 227,0 319,0 319,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"273\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 1.0</text>\n",
       "<text text-anchor=\"middle\" x=\"273\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 2</text>\n",
       "<text text-anchor=\"middle\" x=\"273\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [1, 1]</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>6&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M274.9423,-88.9777C274.6861,-80.7364 274.411,-71.887 274.1507,-63.5153\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"277.6407,-63.1349 273.8316,-53.2485 270.6441,-63.3524 277.6407,-63.1349\"/>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>8</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"429,-53 337,-53 337,0 429,0 429,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"383\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"383\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3</text>\n",
       "<text text-anchor=\"middle\" x=\"383\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 3]</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>6&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M313.7242,-88.9777C324.0806,-79.6376 335.3031,-69.5163 345.639,-60.1947\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"348.2591,-62.5449 353.3411,-53.2485 343.5709,-57.3467 348.2591,-62.5449\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x11dc67610>"
=======
      "text/plain": [
       "True"
>>>>>>> c6d1ee05bc57c5fd54f07ebf1b872e56a7781fab
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "import graphviz\n",
    "\n",
<<<<<<< HEAD
    "\n",
    "data = pd.read_csv('Datasets/tennis.txt', delimiter=\"\\t\", header=None, names=['a', 'b', 'c', 'd', 'e'])\n",
=======
    "# read in the tennis data, need the extra parameters since it's a txt file\n",
    "data = pd.read_csv('./Datasets/tennis.txt', delimiter=\"\\t\", header=None, names=['Outlook', 'Temp', 'Humidity', 'Wind', 'Play'])\n",
>>>>>>> c6d1ee05bc57c5fd54f07ebf1b872e56a7781fab
    "print(data)\n",
    "\n",
    "# encode the data so we can use it with our decision tree\n",
    "data_encoded = data.apply(preprocessing.LabelEncoder().fit_transform)\n",
    "print(data_encoded)\n",
    "\n",
    "# create our decision tree classifier\n",
    "clf = DecisionTreeClassifier(criterion='entropy', max_depth=3)\n",
    "\n",
    "# one_hot_data = pd.get_dummies(data[['a', 'b', 'c', 'd']], drop_first=True)\n",
    "# print(one_hot_data)\n",
    "\n",
    "# classify our data using a decision tree\n",
    "clf.fit(data_encoded[['Outlook', 'Temp', 'Humidity', 'Wind']], data_encoded['Play'])\n",
    "\n",
    "# export our decision tree into data that can be plotted\n",
    "dot_data = export_graphviz(clf, out_file=None, feature_names=['Outlook', 'Temp.', 'Humidity', 'Wind'])\n",
    "\n",
    "# Draw graph\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "#graph.write_png('Images/tennis_tree.png')\n",
    "\n",
    "graph.write_png('original_tree.png')\n",
    "graph.set_size('\"11,12!\"')\n",
    "graph.write_png('resized_tree.png')\n",
    "gvz_graph = graphviz.Source(graph.to_string())\n",
    "gvz_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity: Information Gain between Feature and Target\n",
    "\n",
    "**In groups of 3:** Write a function that takes a Tennis pandas dataframe, one feature (for example Wind) and target column (Decision) as input, then returns the information gain between the feature and the target.\n",
    "\n",
    "Use the hints and starter code given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Outlook  Temp Humidity    Wind Play\n",
      "1      Sunny   Hot     High    Weak   No\n",
      "2      Sunny   Hot     High  Strong   No\n",
      "3   Overcast   Hot     High    Weak  Yes\n",
      "4       Rain  Mild     High    Weak  Yes\n",
      "5       Rain  Cool   Normal    Weak  Yes\n",
      "6       Rain  Cool   Normal  Strong   No\n",
      "7   Overcast  Cool   Normal  Strong  Yes\n",
      "8      Sunny  Mild     High    Weak   No\n",
      "9      Sunny  Cool   Normal    Weak  Yes\n",
      "10      Rain  Mild   Normal    Weak  Yes\n",
      "11     Sunny  Mild   Normal  Strong  Yes\n",
      "12  Overcast  Mild     High  Strong  Yes\n",
      "13  Overcast   Hot   Normal    Weak  Yes\n",
      "14      Rain  Mild     High  Strong   No\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('tennis.txt', delimiter=\"\\t\", header=None, names=['Outlook', 'Temp', 'Humidity', 'Wind', 'Play'])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hint: helper function for entopy\n",
    "import numpy as np\n",
    "\n",
    "def entropy(p):\n",
    "    H = np.array([-i*np.log2(i) for i in p]).sum()\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'No': 0.25, 'Yes': 0.75}\n",
      "{'No': 0.5, 'Yes': 0.5}\n"
     ]
    }
   ],
   "source": [
    "# hint: helper function for a feature and decision and condition of the feature\n",
    "def conditional_prob(df, c1, c2, condition):\n",
    "    df_new = df[df[c1] == condition][c2]\n",
    "    s = df_new.unique()\n",
    "    population_size = len(df_new)\n",
    "    pr = {}\n",
    "    for i in s:\n",
    "        pr[i] = len(df[(df[c1] == condition) & (df[c2]== i)]) / population_size\n",
    "    \n",
    "    return pr\n",
    "        \n",
    "print(conditional_prob(data,'Wind', 'Play', 'Weak'))\n",
    "print(conditional_prob(data, 'Wind', 'Play', 'Strong'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_gain(df, feature, decision):\n",
    "    dict_decision = dict(df[decision].value_counts())\n",
    "    prob_decision = [q for (p,q) in dict_decision.items()]/sum(dict_decision.values())\n",
    "    entropy_decision = entropy(prob_decision)\n",
    "#     print(entropy_decision)\n",
    "    \n",
    "    dict_feature = dict(df[feature].value_counts())\n",
    "    dict_prob_feature = {}\n",
    "    for (p,q) in dict_feature.items():\n",
    "        dict_prob_feature[p] = q/sum(dict_feature.values())\n",
    "#     print(dict_prob_feature)\n",
    "    \n",
    "    conditions = df[feature].unique()\n",
    "    dict_ = {}\n",
    "    for condition in conditions:\n",
    "        dict_[condition] = conditional_prob(df, feature, decision, condition)\n",
    "#     print(dict_)\n",
    "    S = 0\n",
    "    for (i,j) in dict_.items():\n",
    "#         print(i,j)\n",
    "        prob_condition = list(dict_[i].values())\n",
    "#         print(entropy_condition)\n",
    "        S = S + dict_prob_feature[i]*entropy(prob_condition)\n",
    "#         print(dict_prob_feature[i]*entropy(entropy_condition))\n",
    "    print(entropy_decision - S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04812703040826949\n",
      "0.15183550136234159\n",
      "0.02922256565895487\n",
      "0.24674981977443933\n"
     ]
    }
   ],
   "source": [
    "info_gain(data, 'Wind', 'Play')\n",
    "info_gain(data, 'Humidity', 'Play')\n",
    "info_gain(data, 'Temp', 'Play')\n",
    "info_gain(data, 'Outlook', 'Play')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: We can show the information gain between any feature with it self is equal to its entropy: \n",
    "\n",
    "- $I(X, X) = H(X)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5774062828523454\n",
      "1.5774062828523454\n",
      "1.5566567074628228\n",
      "1.5566567074628228\n",
      "1.0\n",
      "1.0\n",
      "0.9852281360342515\n",
      "0.9852281360342515\n",
      "0.9402859586706311\n",
      "0.9402859586706311\n"
     ]
    }
   ],
   "source": [
    "for i in ['Outlook', 'Temp', 'Humidity', 'Wind', 'Play']:\n",
    "    p = [m/sum(data[i].value_counts().to_dict().values()) for m in list(data[i].value_counts().to_dict().values())]\n",
    "    print(entropy(p))\n",
    "    info_gain(data, i, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary:\n",
    "\n",
    "- A decision tree is a decision support tool that uses a tree-like model of decisions and their possible consequences\n",
    "\n",
    "- Decision Trees provide an effective method of Decision Making \n",
    "\n",
    "- The best characteristic of using trees for analytics -> easy to interpret and explain to executives\n",
    "\n",
    "- The mechanism behind Decision Trees is maximizing information gains while have different options "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Resources:\n",
    "\n",
    "- https://sefiks.com/2017/11/20/a-step-by-step-id3-decision-tree-example/\n",
    "\n",
    "- https://heartbeat.fritz.ai/introduction-to-decision-tree-learning-cd604f85e236\n",
    "\n",
    "- https://journals.plos.org/plosone/article/figure/image?id=10.1371/journal.pone.0161696.g002&size=inline\n",
    "\n",
    "- https://medium.com/coinmonks/what-is-entropy-and-why-information-gain-is-matter-4e85d46d2f01\n",
    "\n",
    "DT Visualization:\n",
    "\n",
    "- https://explained.ai/decision-tree-viz/\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Mild': 6, 'Cool': 4, 'Hot': 4}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Temp'].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 4, 4]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data['Temp'].value_counts().to_dict().values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data['Temp'].value_counts().to_dict().values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5566567074628228\n"
     ]
    }
   ],
   "source": [
    "p = [m/sum(data['Temp'].value_counts().to_dict().values()) for m in list(data['Temp'].value_counts().to_dict().values())]\n",
    "\n",
    "print(entropy(p))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.7.6"
=======
   "version": "3.7.5"
>>>>>>> c6d1ee05bc57c5fd54f07ebf1b872e56a7781fab
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
